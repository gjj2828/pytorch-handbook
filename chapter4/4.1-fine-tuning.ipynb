{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch,os,torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, models, transforms\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 Fine tuning 模型微调\n",
    "在前面的介绍卷积神经网络的时候，说到过PyTorch已经为我们训练好了一些经典的网络模型，那么这些预训练好的模型是用来做什么的呢？其实就是为了我们进行微调使用的。\n",
    "\n",
    "## 4.1.1 什么是微调\n",
    "\n",
    "针对于某个任务，自己的训练数据不多，那怎么办？\n",
    "没关系，我们先找到一个同类的别人训练好的模型，把别人现成的训练好了的模型拿过来，换成自己的数据，调整一下参数，再训练一遍，这就是微调（fine-tune）。\n",
    "PyTorch里面提供的经典的网络模型都是官方通过Imagenet的数据集与训练好的数据，如果我们的数据训练数据不够，这些数据是可以作为基础模型来使用的。\n",
    "\n",
    "### 为什么要微调\n",
    "1. 对于数据集本身很小（几千张图片）的情况，从头开始训练具有几千万参数的大型神经网络是不现实的，因为越大的模型对数据量的要求越大，过拟合无法避免。这时候如果还想用上大型神经网络的超强特征提取能力，只能靠微调已经训练好的模型。\n",
    "2. 可以降低训练成本：如果使用导出特征向量的方法进行迁移学习，后期的训练成本非常低，用 CPU 都完全无压力，没有深度学习机器也可以做。\n",
    "3. 前人花很大精力训练出来的模型在大概率上会比你自己从零开始搭的模型要强悍，没有必要重复造轮子。\n",
    "\n",
    "\n",
    "### 迁移学习 Transfer Learning\n",
    "总是有人把 迁移学习和神经网络的训练联系起来，这两个概念刚开始是无关的。\n",
    "迁移学习是机器学习的分支，现在之所以 迁移学习和神经网络联系如此紧密，现在图像识别这块发展的太快效果也太好了，所以几乎所有的迁移学习都是图像识别方向的，所以大家看到的迁移学习基本上都是以神经网络相关的计算机视觉为主，本文中也会以这方面来举例子\n",
    "\n",
    "迁移学习初衷是节省人工标注样本的时间，让模型可以通过一个已有的标记数据的领域向未标记数据领域进行迁移从而训练出适用于该领域的模型，直接对目标域从头开始学习成本太高，我们故而转向运用已有的相关知识来辅助尽快地学习新知识\n",
    "\n",
    "举一个简单的例子就能很好的说明问题，我们学习编程的时候会学习什么？ 语法、特定语言的API、流程处理、面向对象，设计模式，等等\n",
    "\n",
    "这里面语法和API是每一个语言特有的，但是面向对象和设计模式可是通用的，我们学了JAVA，再去学C#，或者Python，面向对象和设计模式是不用去学的，因为原理都是一样的，甚至在学习C#的时候语法都可以少学很多，这就是迁移学习的概念，把统一的概念抽象出来，只学习不同的内容。\n",
    "\n",
    "迁移学习按照学习方式可以分为基于样本的迁移，基于特征的迁移，基于模型的迁移，以及基于关系的迁移，这里就不详细介绍了。\n",
    "\n",
    "### 二者关系\n",
    "其实 \"Transfer Learning\" 和 \"Fine-tune\" 并没有严格的区分，含义可以相互交换，只不过后者似乎更常用于形容迁移学习的后期微调中。\n",
    "我个人的理解，微调应该是迁移学习中的一部分。微调只能说是一个trick。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.2 如何微调\n",
    "对于不同的领域微调的方法也不一样，比如语音识别领域一般微调前几层，图片识别问题微调后面几层，这个原因我这里也只能讲个大概，具体还要大神来解释：\n",
    "\n",
    "对于图片来说，我们CNN的前几层学习到的都是低级的特征，比如，点、线、面，这些低级的特征对于任何图片来说都是可以抽象出来的，所以我们将他作为通用数据，只微调这些低级特征组合起来的高级特征即可，例如，这些点、线、面，组成的是圆还是椭圆，还是正方形，这些代表的含义是我们需要后面训练出来的。\n",
    "\n",
    "对于语音来说，每个单词表达的意思都是一样的，只不过发音或者是单词的拼写不一样，比如 苹果，apple，apfel（德语），都表示的是同一个东西，只不过发音和单词不一样，但是他具体代表的含义是一样的，就是高级特征是相同的，所以我们只要微调低级的特征就可以了。\n",
    "\n",
    "下面只介绍下计算机视觉方向的微调，摘自 [cs231](http://cs231n.github.io/transfer-learning/)\n",
    "\n",
    " - ConvNet as fixed feature extractor.：\n",
    "其实这里有两种做法： \n",
    "1. 使用最后一个fc layer之前的fc layer获得的特征，学习个线性分类器(比如SVM) \n",
    "2. 重新训练最后一个fc layer\n",
    "\n",
    "\n",
    " - Fine-tuning the ConvNet\n",
    " \n",
    "固定前几层的参数，只对最后几层进行fine-tuning,\n",
    " \n",
    "对于上面两种方案有一些微调的小技巧，比如先计算出预训练模型的卷积层对所有训练和测试数据的特征向量，然后抛开预训练模型，只训练自己定制的简配版全连接网络。\n",
    "这个方式的一个好处就是节省计算资源，每次迭代都不会再去跑全部的数据，而只是跑一下简配的全连接\n",
    "\n",
    " \n",
    " - Pretrained models \n",
    " \n",
    "这个其实和第二种是一个意思，不过比较极端，使用整个pre-trained的model作为初始化，然后fine-tuning整个网络而不是某些层，但是这个的计算量是非常大的,就只相当于做了一个初始化。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.3 注意事项\n",
    "\n",
    "1. 新数据集和原始数据集合类似，那么直接可以微调一个最后的FC层或者重新指定一个新的分类器\n",
    "2. 新数据集比较小和原始数据集合差异性比较大，那么可以使用从模型的中部开始训练，只对最后几层进行fine-tuning\n",
    "3. 新数据集比较小和原始数据集合差异性比较大，如果上面方法还是不行的化那么最好是重新训练，只将预训练的模型作为一个新模型初始化的数据\n",
    "4. 新数据集的大小一定要与原始数据集相同，比如CNN中输入的图片大小一定要相同，才不会报错\n",
    "5. 如果数据集大小不同的话，可以在最后的fc层之前添加卷积或者pool层，使得最后的输出与fc层一致，但这样会导致准确度大幅下降，所以不建议这样做\n",
    "6. 对于不同的层可以设置不同的学习率，一般情况下建议，对于使用的原始数据做初始化的层设置的学习率要小于（一般可设置小于10倍）初始化的学习率，这样保证对于已经初始化的数据不会扭曲的过快，而使用初始化学习率的新层可以快速的收敛。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.3 微调实例\n",
    "这里面我们使用官方训练好的resnet50来参加kaggle上面的 [dog breed](https://www.kaggle.com/c/dog-breed-identification) 狗的种类识别来做一个简单微调实例。\n",
    "\n",
    "首先我们需要下载官方的数据解压，只要保持数据的目录结构即可，这里指定一下目录的位置，并且看下内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
       "      <td>boston_bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
       "      <td>dingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
       "      <td>pekinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
       "      <td>bluetick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
       "      <td>golden_retriever</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id             breed\n",
       "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
       "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
       "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
       "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
       "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_ROOT = 'data'\n",
    "all_labels_df = pd.read_csv(os.path.join(DATA_ROOT,'labels.csv'))\n",
    "all_labels_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取狗的分类根据分类进行编号\n",
    "\n",
    "这里定义了两个字典，分别以名字和id作为对应，方便后面处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breeds = all_labels_df.breed.unique()\n",
    "breed2idx = dict((breed,idx) for idx,breed in enumerate(breeds))\n",
    "idx2breed = dict((idx,breed) for idx,breed in enumerate(breeds))\n",
    "len(breeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "添加到列表中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "      <th>label_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
       "      <td>boston_bull</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
       "      <td>dingo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
       "      <td>pekinese</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
       "      <td>bluetick</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
       "      <td>golden_retriever</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id             breed  label_idx\n",
       "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull          0\n",
       "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo          1\n",
       "2  001cdf01b096e06d78e9e5112d419397          pekinese          2\n",
       "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick          3\n",
       "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever          4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels_df['label_idx'] = [breed2idx[b] for b in all_labels_df.breed]\n",
    "all_labels_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于我们的数据集不是官方指定的格式，我们自己定义一个数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogDataset(Dataset):\n",
    "    def __init__(self, labels_df, img_path, transform=None):\n",
    "        self.labels_df = labels_df\n",
    "        self.img_path = img_path\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.labels_df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_name = os.path.join(self.img_path, self.labels_df.id[idx]) + '.jpg'\n",
    "        img = Image.open(image_name)\n",
    "        label = self.labels_df.label_idx[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义一些超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224 # resnet50的输入是224的所以需要将图片统一大小\n",
    "BATCH_SIZE= 256 #这个批次大小需要占用4.6-5g的显存，如果不够的化可以改下批次，如果内存超过10G可以改为512\n",
    "IMG_MEAN = [0.485, 0.456, 0.406]\n",
    "IMG_STD = [0.229, 0.224, 0.225]\n",
    "CUDA=torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义训练和验证数据的图片变换规则"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.RandomResizedCrop(IMG_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMG_MEAN, IMG_STD)\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMG_MEAN, IMG_STD)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们这里只分割10%的数据作为训练时的验证数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = ['train', 'valid']\n",
    "stratified_split = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=0)\n",
    "train_split_idx, val_split_idx = next(iter(stratified_split.split(all_labels_df.id, all_labels_df.breed)))\n",
    "train_df = all_labels_df.iloc[train_split_idx].reset_index()\n",
    "val_df = all_labels_df.iloc[val_split_idx].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用官方的dataloader载入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transforms = {'train':train_transforms, 'valid':val_transforms}\n",
    "\n",
    "train_dataset = DogDataset(train_df, os.path.join(DATA_ROOT,'train'), transform=image_transforms['train'])\n",
    "val_dataset = DogDataset(val_df, os.path.join(DATA_ROOT,'train'), transform=image_transforms['valid'])\n",
    "image_dataset = {'train':train_dataset, 'valid':val_dataset}\n",
    "\n",
    "image_dataloader = {x:DataLoader(image_dataset[x],batch_size=BATCH_SIZE,shuffle=True,num_workers=0) for x in dataset_names}\n",
    "dataset_sizes = {x:len(image_dataset[x]) for x in dataset_names}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开始配置网络，由于ImageNet是识别1000个物体，我们的狗的分类一共只有120，所以需要对模型的最后一层全连接层进行微调，将输出从1000改为120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=2048, out_features=1000, bias=True)\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=120, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# model_ft = models.resnet50(pretrained=True) # 这里自动下载官方的预训练模型，并且\n",
    "# model_ft = models.resnet50(weights=models.ResNet50_Weights.DEFAULT) # 这里自动下载官方的预训练模型，并且\n",
    "model_ft = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1) # 这里自动下载官方的预训练模型，并且\n",
    "# 将所有的参数层进行冻结\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False\n",
    "# 这里打印下全连接层的信息\n",
    "print(model_ft.fc)\n",
    "num_fc_ftr = model_ft.fc.in_features #获取到fc层的输入\n",
    "model_ft.fc = nn.Linear(num_fc_ftr, len(breeds)) # 定义一个新的FC层\n",
    "model_ft=model_ft.to(DEVICE)# 放到设备中\n",
    "print(model_ft) # 最后再打印一下新的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置训练参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params':model_ft.fc.parameters()}\n",
    "], lr=0.001)#指定 新加的fc层的学习率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,device, train_loader, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        x,y= data\n",
    "        x=x.to(device)\n",
    "        y=y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_hat= model(x)\n",
    "        loss = criterion(y_hat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print ('Train Epoch: {}\\t Loss: {:.6f}'.format(epoch,loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义测试函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    is_print = True\n",
    "    with torch.no_grad():\n",
    "        for i,data in enumerate(test_loader):          \n",
    "            x,y= data\n",
    "            x=x.to(device)\n",
    "            y=y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(x)\n",
    "            # if is_print:\n",
    "                # print(len(y_hat))\n",
    "                # print(y)\n",
    "            test_loss += criterion(y_hat, y).item() # sum up batch loss\n",
    "            pred = y_hat.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            if is_print:\n",
    "                # print(pred)\n",
    "                print(pred.eq(y.view_as(pred)).sum().item())\n",
    "                pred2 = y_hat.max(1)[1]\n",
    "                # print(pred2.eq(y).sum().item())\n",
    "                print(pred2.eq(y).sum())\n",
    "                is_print = False\n",
    "            correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(val_dataset),\n",
    "        100. * correct / len(val_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练9次，看看效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1\t Loss: 2.730890\n",
      "CPU times: total: 9min 27s\n",
      "Wall time: 2min 6s\n",
      "\n",
      "Test set: Average loss: 0.0079, Accuracy: 689/1023 (67%)\n",
      "\n",
      "Train Epoch: 2\t Loss: 1.895483\n",
      "CPU times: total: 8min 33s\n",
      "Wall time: 1min 27s\n",
      "\n",
      "Test set: Average loss: 0.0048, Accuracy: 749/1023 (73%)\n",
      "\n",
      "Train Epoch: 3\t Loss: 1.786441\n",
      "CPU times: total: 9min 3s\n",
      "Wall time: 1min 33s\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 793/1023 (78%)\n",
      "\n",
      "Train Epoch: 4\t Loss: 1.603706\n",
      "CPU times: total: 9min 16s\n",
      "Wall time: 1min 35s\n",
      "\n",
      "Test set: Average loss: 0.0031, Accuracy: 823/1023 (80%)\n",
      "\n",
      "Train Epoch: 5\t Loss: 1.452764\n",
      "CPU times: total: 9min 19s\n",
      "Wall time: 1min 36s\n",
      "\n",
      "Test set: Average loss: 0.0030, Accuracy: 821/1023 (80%)\n",
      "\n",
      "Train Epoch: 6\t Loss: 1.303778\n",
      "CPU times: total: 9min 24s\n",
      "Wall time: 1min 36s\n",
      "\n",
      "Test set: Average loss: 0.0027, Accuracy: 831/1023 (81%)\n",
      "\n",
      "Train Epoch: 7\t Loss: 1.481840\n",
      "CPU times: total: 9min 22s\n",
      "Wall time: 1min 36s\n",
      "\n",
      "Test set: Average loss: 0.0027, Accuracy: 827/1023 (81%)\n",
      "\n",
      "Train Epoch: 8\t Loss: 1.377482\n",
      "CPU times: total: 8min 51s\n",
      "Wall time: 1min 36s\n",
      "\n",
      "Test set: Average loss: 0.0026, Accuracy: 820/1023 (80%)\n",
      "\n",
      "Train Epoch: 9\t Loss: 1.109441\n",
      "CPU times: total: 8min 36s\n",
      "Wall time: 1min 27s\n",
      "\n",
      "Test set: Average loss: 0.0025, Accuracy: 827/1023 (81%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 10):\n",
    "    %time train(model=model_ft,device=DEVICE, train_loader=image_dataloader[\"train\"],epoch=epoch)\n",
    "    test(model=model_ft, device=DEVICE, test_loader=image_dataloader[\"valid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(4, 3)\n",
    "print(a.size(0))\n",
    "# a.max(1,  keepdim=True)\n",
    "# a.max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211\n",
      "tensor(211, device='cuda:0')\n",
      "\n",
      "Test set: Average loss: 0.0025, Accuracy: 827/1023 (81%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(model=model_ft, device=DEVICE, test_loader=image_dataloader[\"valid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 46.9 ms\n",
      "Wall time: 45.4 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "499999500000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %time 2**128\n",
    "n = 1000000\n",
    "%time sum(range(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1\t Loss: 1.395657\n",
      "CPU times: total: 11min 55s\n",
      "Wall time: 2min 9s\n"
     ]
    }
   ],
   "source": [
    "%time train(model=model_ft,device=DEVICE, train_loader=image_dataloader[\"train\"],epoch=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们看到只训练了9次就达到了80%的准确率，效果还是可以的。\n",
    "\n",
    "但是每次训练都需要将一张图片在全部网络中进行计算，而且计算的结果每次都是一样的，这样浪费了很多计算的资源。\n",
    "下面我们就将这些不进行反向传播或者说不更新网络权重参数层的计算结果保存下来，这样我们以后使用的时候就可以直接将这些结果输入到FC层或者以这些结果构建新的网络层，省去了计算的时间，并且这样如果只训练全连接层，CPU就可以完成了。\n",
    "## 4.1.4 固定层的向量导出\n",
    "[PyTorch论坛](https://discuss.pytorch.org/t/can-i-get-the-middle-layers-output-if-i-use-the-sequential-module/7070)中说到可以使用自己手动实现模型中的forward参数，这样看起来是很简便的，但是这样处理起来很麻烦，不建议这样使用。\n",
    "\n",
    "这里我们就要采用PyTorch比较高级的API，hook来处理了，我们要先定义一个hook函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_list= [] # 这里存放所有的输出\n",
    "def hook(module, input, output):\n",
    "    #input是一个tuple代表顺序代表每一个输入项，我们这里只有一项，所以直接获取\n",
    "    #需要全部的参数信息可以使用这个打印\n",
    "    # for val in input:\n",
    "    #    print(\"input val:\",val)\n",
    "    # print(len(input))\n",
    "    for i in range(input[0].size(0)):\n",
    "        in_list.append(input[0][i].cpu().numpy())\n",
    "def hook2(module, input, output):\n",
    "    #input是一个tuple代表顺序代表每一个输入项，我们这里只有一项，所以直接获取\n",
    "    #需要全部的参数信息可以使用这个打印\n",
    "    # for val in input:\n",
    "    #    print(\"input val:\",val)\n",
    "    # print(len(input))\n",
    "    for i in range(input[0].size(0)):\n",
    "        in_list.append(input[0][i].cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在相应的层注册hook函数，保证函数能够正常工作，我们这里直接hook 全连接层前面的pool层，获取pool层的输入数据，这样会获得更多的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x27d6c6e5c90>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft.avgpool.register_forward_hook(hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(0, <function __main__.hook(module, input, output)>),\n",
       "             (1, <function __main__.hook(module, input, output)>),\n",
       "             (2, <function __main__.hook(module, input, output)>),\n",
       "             (3, <function __main__.hook(module, input, output)>),\n",
       "             (4, <function __main__.hook(module, input, output)>),\n",
       "             (5, <function __main__.hook(module, input, output)>),\n",
       "             (6, <function __main__.hook2(module, input, output)>),\n",
       "             (7, <function __main__.hook(module, input, output)>)])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft.avgpool._forward_hooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开始获取输出，这里我们因为不需要反向传播，所以直接可以使用no_grad嵌套"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input val: tensor([[[[0.0000e+00, 1.7107e-01, 1.5489e-01,  ..., 2.0708e-01,\n",
      "           4.7155e-01, 1.2893e-01],\n",
      "          [7.5821e-02, 8.6188e-01, 3.2726e-01,  ..., 2.8304e-01,\n",
      "           6.9909e-02, 0.0000e+00],\n",
      "          [1.2361e-01, 9.0097e-01, 2.7295e-01,  ..., 1.4892e-01,\n",
      "           1.6621e-01, 0.0000e+00],\n",
      "          ...,\n",
      "          [6.1025e-01, 1.1013e+00, 1.3795e+00,  ..., 1.9458e-01,\n",
      "           0.0000e+00, 4.0041e-01],\n",
      "          [6.0972e-01, 1.6565e-01, 1.9404e-01,  ..., 3.1084e-01,\n",
      "           8.5563e-01, 5.7787e-01],\n",
      "          [0.0000e+00, 1.1395e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[1.9668e-01, 3.8674e-01, 1.7656e-01,  ..., 1.3005e-01,\n",
      "           0.0000e+00, 1.8812e-01],\n",
      "          [1.4592e+00, 1.0383e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           4.2391e-01, 0.0000e+00],\n",
      "          [1.9192e+00, 1.0317e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           7.9243e-02, 0.0000e+00],\n",
      "          ...,\n",
      "          [3.0019e-01, 8.5357e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 1.6379e-01]],\n",
      "\n",
      "         [[7.5836e-01, 1.8677e+00, 1.2189e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.5870e-01, 1.1552e+00, 1.3076e+00,  ..., 2.2169e-01,\n",
      "           2.6931e-01, 3.3942e-01],\n",
      "          [0.0000e+00, 1.0933e+00, 2.1498e-01,  ..., 1.0656e-01,\n",
      "           2.1008e-01, 0.0000e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 3.4121e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           4.9606e-01, 3.1493e-01],\n",
      "          [0.0000e+00, 2.3638e-01, 0.0000e+00,  ..., 1.9090e-02,\n",
      "           1.4938e-01, 1.0132e-02],\n",
      "          [0.0000e+00, 1.3831e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 6.3308e-01,  ..., 2.7213e-01,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 1.7444e-02, 4.0581e-01,  ..., 9.2937e-01,\n",
      "           1.0773e+00, 1.3756e+00],\n",
      "          [0.0000e+00, 2.9663e-01, 4.4196e-01,  ..., 1.4264e+00,\n",
      "           1.4772e+00, 1.8018e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 1.6354e-01, 2.5090e-01,  ..., 2.2131e-01,\n",
      "           5.3063e-01, 9.9808e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.9611e-01,\n",
      "           7.9034e-01, 6.9270e-01],\n",
      "          [2.0462e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           2.2677e-01, 9.1139e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 3.4349e-01,  ..., 2.3250e-01,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.0388e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [8.3213e-01, 6.6813e-01, 6.8367e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [6.7270e-01, 1.2542e+00, 1.1436e+00,  ..., 1.5623e-01,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[2.1747e-01, 9.9605e-01, 4.3874e-01,  ..., 0.0000e+00,\n",
      "           2.3735e-01, 0.0000e+00],\n",
      "          [7.7194e-01, 1.4284e+00, 1.8384e-01,  ..., 1.4678e-01,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [6.7760e-01, 1.3798e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 3.7845e-01, 2.1284e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 7.5741e-01,  ..., 1.0081e-01,\n",
      "           4.0320e-01, 4.0416e-01],\n",
      "          [0.0000e+00, 3.2824e-01, 8.2485e-01,  ..., 6.5302e-01,\n",
      "           5.7086e-01, 3.6827e-01]]],\n",
      "\n",
      "\n",
      "        [[[0.0000e+00, 1.0672e-01, 7.3649e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 2.4079e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.1687e-01, 2.3399e-01, 5.4602e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 6.7010e-01],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 1.1945e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 4.4107e-01,  ..., 2.2269e-01,\n",
      "           2.6163e-01, 5.4217e-01],\n",
      "          [0.0000e+00, 2.4296e-01, 5.6495e-01,  ..., 1.7951e-01,\n",
      "           2.6036e-01, 5.2212e-01]],\n",
      "\n",
      "         [[9.5635e-02, 8.4861e-01, 5.3477e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [8.9523e-01, 7.7715e-01, 8.9472e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 3.5358e-01],\n",
      "          [0.0000e+00, 8.5150e-01, 7.2458e-01,  ..., 1.3439e-01,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 1.1488e-01,  ..., 1.2182e-02,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[7.5419e-02, 4.0090e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           9.8907e-02, 1.2416e-01],\n",
      "          [0.0000e+00, 1.6266e-01, 3.3312e-01,  ..., 1.3608e-01,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.0444e+00, 2.4528e-01, 6.6293e-01,  ..., 1.1285e+00,\n",
      "           4.7616e-01, 1.1132e-01],\n",
      "          ...,\n",
      "          [0.0000e+00, 2.5752e-02, 1.1880e+00,  ..., 3.9686e-02,\n",
      "           3.9569e-01, 5.5317e-01],\n",
      "          [2.1393e-01, 0.0000e+00, 1.2539e+00,  ..., 5.2734e-01,\n",
      "           2.3495e-01, 6.7296e-01],\n",
      "          [4.8258e-01, 1.2715e-01, 8.5157e-01,  ..., 8.2345e-02,\n",
      "           4.6705e-01, 3.5213e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 2.1814e-01,  ..., 1.0949e+00,\n",
      "           8.0120e-01, 6.4080e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 1.4225e-01,  ..., 1.4871e+00,\n",
      "           1.1047e+00, 8.5270e-01],\n",
      "          [0.0000e+00, 2.0252e-02, 1.3188e-01,  ..., 2.1666e+00,\n",
      "           1.4043e+00, 7.0179e-01],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 5.6489e-02,  ..., 1.6077e+00,\n",
      "           1.9185e+00, 9.9550e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 2.9227e-01,  ..., 1.2150e+00,\n",
      "           3.3014e-01, 9.4223e-02],\n",
      "          [0.0000e+00, 0.0000e+00, 1.0253e-01,  ..., 7.6953e-01,\n",
      "           2.1473e-02, 0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 7.6875e-01,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.3679e-01,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.5230e-01,\n",
      "           5.2132e-02, 1.2361e-01],\n",
      "          ...,\n",
      "          [0.0000e+00, 2.0204e-01, 6.8101e-01,  ..., 6.5193e-01,\n",
      "           1.4822e+00, 2.3073e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 2.8282e-01,  ..., 6.6019e-01,\n",
      "           1.4481e+00, 1.6868e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 3.1981e-02,  ..., 7.7890e-01,\n",
      "           1.1754e+00, 1.3944e+00]],\n",
      "\n",
      "         [[0.0000e+00, 3.7683e-01, 0.0000e+00,  ..., 3.7628e-01,\n",
      "           4.6825e-01, 2.1113e-01],\n",
      "          [3.5138e-01, 2.0402e-01, 0.0000e+00,  ..., 1.1402e-01,\n",
      "           5.1451e-01, 1.0572e+00],\n",
      "          [0.0000e+00, 4.4225e-02, 0.0000e+00,  ..., 1.7148e-01,\n",
      "           5.8042e-01, 4.8798e-01],\n",
      "          ...,\n",
      "          [0.0000e+00, 1.0964e-02, 1.1375e-02,  ..., 0.0000e+00,\n",
      "           6.7220e-02, 0.0000e+00],\n",
      "          [0.0000e+00, 6.3285e-02, 4.3164e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[0.0000e+00, 2.4158e-01, 3.8256e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 2.1934e-01, 9.1303e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 9.4923e-02, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 4.6205e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [7.2530e-02, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 3.2064e-02, 2.5243e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [6.5091e-01, 7.1198e-01, 1.5315e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.2935e-01, 7.6746e-02, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.1869e-01,\n",
      "           4.0284e-01, 1.6362e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           4.2856e-01, 7.8773e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.1039e-01,\n",
      "           6.4716e-01, 6.2649e-01],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 3.1478e-01,  ..., 6.3262e-01,\n",
      "           6.3606e-01, 2.8036e-01],\n",
      "          [4.9939e-01, 4.6349e-02, 1.1448e+00,  ..., 1.0123e+00,\n",
      "           2.6320e-01, 9.3335e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 1.1270e+00,  ..., 6.3475e-01,\n",
      "           1.0971e-01, 1.1921e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 3.0309e-01,  ..., 1.0465e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 3.6264e-01,  ..., 4.0561e-01,\n",
      "           1.8873e-01, 2.8296e-02],\n",
      "          [1.0929e-02, 0.0000e+00, 4.8487e-01,  ..., 6.5712e-01,\n",
      "           9.9113e-01, 1.0592e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 7.8080e-01,\n",
      "           1.0319e+00, 7.1812e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.2586e+00,\n",
      "           1.7865e+00, 1.3775e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 9.3873e-01,\n",
      "           1.0860e+00, 8.8000e-01]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 8.1495e-01,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.4493e-01, 6.4769e-01, 6.9307e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.0668e+00, 1.1757e+00, 1.0960e+00,  ..., 0.0000e+00,\n",
      "           1.4750e-01, 0.0000e+00],\n",
      "          ...,\n",
      "          [1.8098e+00, 4.8335e-01, 5.7401e-01,  ..., 7.0927e-01,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.5904e-01, 2.6163e-01, 0.0000e+00,  ..., 1.0823e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           3.1136e-01, 1.1818e+00]],\n",
      "\n",
      "         [[7.5734e-02, 3.3475e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           2.6511e-01, 2.0285e-01],\n",
      "          [0.0000e+00, 2.1763e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           3.5608e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           2.3680e-01, 0.0000e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 1.1104e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[8.6422e-01, 2.2707e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [4.5571e-01, 1.0058e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.5456e+00, 1.1352e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           1.1783e-02, 0.0000e+00],\n",
      "          ...,\n",
      "          [4.7112e-01, 1.3404e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[7.4582e-01, 7.9021e-01, 1.7013e+00,  ..., 4.1337e-01,\n",
      "           1.1095e+00, 7.8964e-01],\n",
      "          [1.3594e+00, 4.6458e-03, 8.1735e-01,  ..., 2.0760e+00,\n",
      "           9.2109e-01, 9.0529e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.1612e-01,\n",
      "           9.0027e-01, 4.5875e-01],\n",
      "          ...,\n",
      "          [1.6674e+00, 1.0909e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           6.3070e-01, 1.6322e-01],\n",
      "          [1.6447e+00, 6.9870e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           9.7926e-01, 2.4009e-01],\n",
      "          [9.0850e-01, 1.0365e+00, 2.8584e-01,  ..., 0.0000e+00,\n",
      "           3.3253e-01, 0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.0654e-01,\n",
      "           4.4331e-01, 4.0000e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.4770e-01,\n",
      "           7.0676e-03, 2.9493e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.0859e-02,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 2.4799e-01, 6.3379e-03,  ..., 3.2387e-01,\n",
      "           7.4628e-01, 5.5655e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 4.0324e-02,  ..., 2.9972e+00,\n",
      "           2.9217e+00, 2.2931e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.0139e+00,\n",
      "           3.0281e+00, 1.3902e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000e+00, 2.3879e-01, 3.3389e-01,  ..., 1.2548e+00,\n",
      "           1.2302e+00, 7.7350e-01],\n",
      "          [9.2022e-02, 0.0000e+00, 5.2557e-01,  ..., 2.4019e+00,\n",
      "           1.3550e+00, 1.1537e+00],\n",
      "          [0.0000e+00, 1.1991e-01, 8.9083e-01,  ..., 1.6909e+00,\n",
      "           1.4089e+00, 1.1492e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 2.6373e-02, 5.7183e-01,  ..., 1.2398e+00,\n",
      "           2.2401e+00, 1.2948e+00],\n",
      "          [1.2034e-02, 1.0975e-01, 7.8093e-01,  ..., 1.2517e+00,\n",
      "           9.8769e-01, 4.4802e-01],\n",
      "          [8.5415e-02, 1.1284e-01, 5.8180e-01,  ..., 7.7723e-01,\n",
      "           6.8611e-02, 0.0000e+00]],\n",
      "\n",
      "         [[1.2990e+00, 1.1929e+00, 7.7807e-01,  ..., 3.2690e-01,\n",
      "           7.0719e-02, 0.0000e+00],\n",
      "          [7.7590e-01, 9.3856e-01, 9.1516e-01,  ..., 3.2646e-01,\n",
      "           4.0518e-01, 2.6690e-01],\n",
      "          [1.3344e+00, 1.2149e+00, 7.1119e-01,  ..., 2.5210e-01,\n",
      "           3.5886e-01, 7.4709e-01],\n",
      "          ...,\n",
      "          [1.8934e+00, 3.0852e+00, 1.4566e+00,  ..., 1.5490e+00,\n",
      "           9.9228e-01, 1.0451e+00],\n",
      "          [4.5958e-01, 1.2001e+00, 6.6769e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 4.0338e-02, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[1.5386e-01, 4.1849e-01, 1.0601e+00,  ..., 1.0777e+00,\n",
      "           3.6405e-01, 6.6740e-02],\n",
      "          [0.0000e+00, 7.8420e-01, 1.1311e+00,  ..., 1.1553e+00,\n",
      "           3.6125e-01, 0.0000e+00],\n",
      "          [2.5198e-01, 5.7752e-01, 8.5191e-01,  ..., 9.2286e-01,\n",
      "           1.7563e-01, 0.0000e+00],\n",
      "          ...,\n",
      "          [6.2580e-01, 6.8026e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.1487e-01, 5.2504e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           6.9484e-02, 0.0000e+00],\n",
      "          [0.0000e+00, 1.5194e-01, 0.0000e+00,  ..., 6.1490e-01,\n",
      "           5.9751e-01, 0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           2.7958e-02, 6.7166e-02],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           1.6670e-01, 3.2007e-01],\n",
      "          [2.1287e-01, 1.0035e+00, 2.1023e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.9637e-02, 8.8415e-01, 1.8457e-01,  ..., 0.0000e+00,\n",
      "           3.0577e-02, 0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           1.5660e+00, 2.0760e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.1603e-01,\n",
      "           2.5479e-02, 6.4923e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.9300e-01,\n",
      "           2.5725e-01, 3.2703e-01],\n",
      "          ...,\n",
      "          [1.7235e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 4.7095e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           6.9962e-01, 4.1181e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           4.0170e-01, 3.7505e-02]],\n",
      "\n",
      "         [[3.5351e-01, 2.3049e-02, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 2.7939e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.4103e-01, 3.1385e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           1.5128e-01, 0.0000e+00],\n",
      "          [3.1718e-01, 2.5693e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.0776e-01, 4.7315e-02, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [1.7926e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[6.5695e-02, 6.6167e-01, 1.3784e+00,  ..., 6.0507e-01,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 4.6824e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 4.0213e-01, 7.5356e-01,  ..., 5.9723e-01,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [6.1461e-01, 6.1166e-01, 5.5330e-01,  ..., 1.5076e-01,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [7.6190e-01, 9.6772e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.4501e+00, 1.9001e+00, 1.5223e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[7.4060e-01, 1.1430e+00, 1.1448e+00,  ..., 4.2838e-01,\n",
      "           3.0326e-01, 6.5232e-02],\n",
      "          [1.5014e-01, 6.0240e-01, 2.6122e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.8801e-01, 4.0955e-01, 4.6768e-01,  ..., 1.3403e-01,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [4.1440e-01, 2.9383e-01, 3.3052e-01,  ..., 2.7175e-01,\n",
      "           6.5363e-01, 6.3175e-01],\n",
      "          [1.3862e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.4407e-01,\n",
      "           0.0000e+00, 0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[1.6231e-01, 6.7919e-01, 2.8835e-01,  ..., 1.2779e+00,\n",
      "           8.7681e-01, 2.8562e-01],\n",
      "          [1.2493e-01, 1.0069e-01, 8.6205e-02,  ..., 8.5073e-01,\n",
      "           4.3433e-01, 0.0000e+00],\n",
      "          [3.7033e-01, 4.3307e-01, 2.7600e-01,  ..., 1.8700e-01,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [7.6226e-01, 8.7919e-02, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.1567e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.9942e-01, 2.9871e-01, 2.4119e-01,  ..., 2.4215e-01,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[8.0774e-01, 1.8779e+00, 1.1266e+00,  ..., 5.5778e-02,\n",
      "           9.6726e-01, 7.0701e-01],\n",
      "          [1.5604e+00, 1.2578e+00, 0.0000e+00,  ..., 4.1298e-01,\n",
      "           5.0391e-01, 6.9936e-02],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0028e-01,\n",
      "           2.3600e-01, 0.0000e+00],\n",
      "          ...,\n",
      "          [6.5875e-01, 7.4265e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           6.0794e-01, 1.3932e+00],\n",
      "          [8.9085e-01, 1.3705e+00, 5.9917e-01,  ..., 4.3860e-01,\n",
      "           5.0623e-01, 1.5975e+00],\n",
      "          [0.0000e+00, 5.8216e-01, 1.4725e+00,  ..., 9.9683e-01,\n",
      "           6.6970e-01, 2.1452e-01]],\n",
      "\n",
      "         [[0.0000e+00, 1.7983e-01, 7.8169e-01,  ..., 1.7335e+00,\n",
      "           9.1879e-01, 3.2397e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.4630e-01,\n",
      "           2.9525e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.6962e-01,\n",
      "           0.0000e+00, 2.7621e-01],\n",
      "          ...,\n",
      "          [1.0468e+00, 2.8986e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 3.3685e-01],\n",
      "          [1.8219e-01, 7.9817e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 6.3493e-01,\n",
      "           2.3498e-01, 8.4366e-02],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.1082e+00,\n",
      "           5.8690e-01, 4.7013e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.3932e-01,\n",
      "           1.3315e+00, 9.1014e-01],\n",
      "          ...,\n",
      "          [0.0000e+00, 1.4913e+00, 9.7785e-01,  ..., 2.8181e-01,\n",
      "           1.2143e+00, 1.6370e+00],\n",
      "          [7.0952e-02, 1.4162e+00, 1.9963e+00,  ..., 0.0000e+00,\n",
      "           4.6052e-01, 4.8215e-01],\n",
      "          [0.0000e+00, 2.9994e-01, 1.3400e+00,  ..., 0.0000e+00,\n",
      "           1.4994e-01, 2.3159e-01]],\n",
      "\n",
      "         [[1.2679e-01, 4.7844e-01, 0.0000e+00,  ..., 1.8907e+00,\n",
      "           2.2880e+00, 1.4714e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.2036e+00,\n",
      "           1.4126e+00, 9.6054e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 7.0908e-01,\n",
      "           4.9496e-01, 3.7412e-01],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           4.9428e-02, 2.4063e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.6671e-01,\n",
      "           5.7702e-01, 4.1336e-01]],\n",
      "\n",
      "         [[0.0000e+00, 2.8713e-01, 0.0000e+00,  ..., 7.0141e-01,\n",
      "           9.9156e-01, 6.1916e-01],\n",
      "          [2.0201e-01, 5.1694e-01, 0.0000e+00,  ..., 7.6653e-01,\n",
      "           1.6516e+00, 9.4927e-01],\n",
      "          [3.0929e-01, 5.7983e-02, 2.1014e-01,  ..., 1.6199e+00,\n",
      "           1.5071e+00, 8.8687e-01],\n",
      "          ...,\n",
      "          [5.8124e-01, 7.0555e-01, 1.6344e+00,  ..., 2.1730e+00,\n",
      "           1.5665e+00, 1.1262e+00],\n",
      "          [2.3198e-03, 0.0000e+00, 0.0000e+00,  ..., 1.2240e+00,\n",
      "           9.6689e-03, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 4.3997e-01,  ..., 7.1220e-01,\n",
      "           0.0000e+00, 0.0000e+00]]]], device='cuda:0')\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:6\u001b[0m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\python3.10\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\python3.10\\lib\\site-packages\\torchvision\\models\\resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\python3.10\\lib\\site-packages\\torchvision\\models\\resnet.py:278\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    275\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n\u001b[0;32m    276\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer4(x)\n\u001b[1;32m--> 278\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mavgpool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    280\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(x)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\python3.10\\lib\\site-packages\\torch\\nn\\modules\\module.py:1547\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1545\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, args, kwargs, result)\n\u001b[0;32m   1546\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1547\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hook_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1550\u001b[0m     result \u001b[38;5;241m=\u001b[39m hook_result\n",
      "Cell \u001b[1;32mIn[56], line 7\u001b[0m, in \u001b[0;36mhook\u001b[1;34m(module, input, output)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhook\u001b[39m(module, \u001b[38;5;28minput\u001b[39m, output):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m#input是一个tuple代表顺序代表每一个输入项，我们这里只有一项，所以直接获取\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m#需要全部的参数信息可以使用这个打印\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# for val in input:\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m#    print(\"input val:\",val)\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m())\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28minput\u001b[39m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)):\n\u001b[0;32m      9\u001b[0m         in_list\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28minput\u001b[39m[\u001b[38;5;241m0\u001b[39m][i]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with torch.no_grad():\n",
    "    for batch_idx, data in enumerate(image_dataloader[\"train\"]):\n",
    "        x,y= data\n",
    "        x=x.to(DEVICE)\n",
    "        y=y.to(DEVICE)\n",
    "        y_hat = model_ft(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features=np.array(in_list)\n",
    "np.save(\"features\",features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这样再训练时我们只需将这个数组读出来，然后可以直接使用这个数组再输入到linear或者我们前面讲到的sigmod层就可以了。\n",
    "\n",
    "我们在这里在pool层前获取了更多的特征，可以将这些特征使用更高级的分类器，例如SVM，树型的分类器进行分类。\n",
    "\n",
    "以上就是针对于计算机视觉方向的微调介绍，对于NLP方向来讲fastai的创始人Jeremy 在今年出发布了ULMFiT可以作为很好的参考\n",
    "具体请看这两个链接：\n",
    "\n",
    "[fast.ai官方blog](https://nlp.fast.ai/)，[原论文：Universal Language Model Fine-tuning for Text Classification](https://arxiv.org/abs/1801.06146)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
